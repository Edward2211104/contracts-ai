# Puerto del servicio LLM Python
LLM_API_PORT=4050

# Proveedor: "ollama" o "openai"
LLM_PROVIDER=ollama

# Config para Ollama (local)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1

# Config para OpenAI (solo si LLM_PROVIDER=openai)
OPENAI_API_KEY=PUT_YOUR_API_KEY_HERE
OPENAI_MODEL=gpt-4.1-mini
UPSTREAM_LLM_BASE_URL=http://localhost:1234
UPSTREAM_LLM_MODEL=openai/gpt-oss-20b
